{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyL3m4BdQSjJ89Bo/v/hLA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahd1995913/-caesar_cipher/blob/main/IEEE4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@abhishekjainindore24/data-augmentation-00c72f5f4c54"
      ],
      "metadata": {
        "id": "kxG4hFJj9w7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChBt00NwwykO",
        "outputId": "f55bb0a1-472f-4eaf-99aa-808024460447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the path to the dataset\n",
        "data_dir = '/content/drive/MyDrive/strawberry'"
      ],
      "metadata": {
        "id": "T-Djn5htxkXZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "img_height, img_width = 150, 150\n",
        "batch_size = 32\n",
        "\n",
        "# Step 3: Define Data Augmentation Transformations\n",
        "# Data generator for training with data augmentation\n",
        "train_datagen_augmented = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "jpnajLtbxqsA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Prepare the Dataset\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the path to the dataset\n",
        "data_dir = '/content/drive/MyDrive/strawberry'\n",
        "\n",
        "# Set parameters\n",
        "img_height, img_width = 150, 150\n",
        "batch_size = 32\n",
        "\n",
        "# Step 3: Define Data Augmentation Transformations\n",
        "# Data generator for training with data augmentation\n",
        "train_datagen_augmented = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Data generator for training without data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Data generator for validation\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load the training data\n",
        "train_generator_augmented = train_datagen_augmented.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Step 4: Build and Compile the CNN Model\n",
        "def build_model(num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(img_height, img_width, 3)),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate the model with 9 output classes\n",
        "num_classes = 9\n",
        "model_augmented = build_model(num_classes)\n",
        "model_non_augmented = build_model(num_classes)\n",
        "\n",
        "# Step 5: Train the Models\n",
        "# Training with data augmentation\n",
        "history_augmented = model_augmented.fit(\n",
        "    train_generator_augmented,\n",
        "    steps_per_epoch=train_generator_augmented.samples // batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Training without data augmentation\n",
        "history_non_augmented = model_non_augmented.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Step 6: Compare Performance\n",
        "# Plotting the accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_augmented.history['accuracy'], label='Augmented Training Accuracy')\n",
        "plt.plot(history_augmented.history['val_accuracy'], label='Augmented Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy with Augmentation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_non_augmented.history['accuracy'], label='Non-Augmented Training Accuracy')\n",
        "plt.plot(history_non_augmented.history['val_accuracy'], label='Non-Augmented Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy without Augmentation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plotting the loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_augmented.history['loss'], label='Augmented Training Loss')\n",
        "plt.plot(history_augmented.history['val_loss'], label='Augmented Validation Loss')\n",
        "plt.title('Training and Validation Loss with Augmentation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_non_augmented.history['loss'], label='Non-Augmented Training Loss')\n",
        "plt.plot(history_non_augmented.history['val_loss'], label='Non-Augmented Validation Loss')\n",
        "plt.title('Training and Validation Loss without Augmentation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Q8uOOVxw0Z",
        "outputId": "2e6c47c8-3dc2-499e-c30e-04f696f50caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 2258 images belonging to 9 classes.\n",
            "Found 2258 images belonging to 9 classes.\n",
            "Found 560 images belonging to 9 classes.\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1261s\u001b[0m 17s/step - accuracy: 0.3443 - loss: 1.7811 - val_accuracy: 0.5184 - val_loss: 1.3365\n",
            "Epoch 2/30\n",
            "\u001b[1m 1/70\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:18\u001b[0m 3s/step - accuracy: 0.7188 - loss: 1.0242"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 845ms/step - accuracy: 0.7188 - loss: 1.0242 - val_accuracy: 0.2500 - val_loss: 1.6985\n",
            "Epoch 3/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 5s/step - accuracy: 0.5593 - loss: 1.2075 - val_accuracy: 0.6581 - val_loss: 1.1794\n",
            "Epoch 4/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 541ms/step - accuracy: 0.6250 - loss: 0.9438 - val_accuracy: 0.6875 - val_loss: 1.3861\n",
            "Epoch 5/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 5s/step - accuracy: 0.7268 - loss: 0.8425 - val_accuracy: 0.6801 - val_loss: 0.9369\n",
            "Epoch 6/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.8086 - val_accuracy: 0.8750 - val_loss: 0.4074\n",
            "Epoch 7/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 5s/step - accuracy: 0.7731 - loss: 0.6488 - val_accuracy: 0.7353 - val_loss: 0.8089\n",
            "Epoch 8/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 537ms/step - accuracy: 0.7188 - loss: 0.8354 - val_accuracy: 0.7500 - val_loss: 0.5211\n",
            "Epoch 9/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 5s/step - accuracy: 0.7848 - loss: 0.6195 - val_accuracy: 0.7426 - val_loss: 0.7287\n",
            "Epoch 10/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 529ms/step - accuracy: 0.8750 - loss: 0.4692 - val_accuracy: 0.9375 - val_loss: 0.5380\n",
            "Epoch 11/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 5s/step - accuracy: 0.8067 - loss: 0.5578 - val_accuracy: 0.7206 - val_loss: 0.7901\n",
            "Epoch 12/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 394ms/step - accuracy: 0.9062 - loss: 0.4328 - val_accuracy: 0.7500 - val_loss: 0.7130\n",
            "Epoch 13/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 5s/step - accuracy: 0.8260 - loss: 0.4981 - val_accuracy: 0.7298 - val_loss: 0.8688\n",
            "Epoch 14/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.6095 - val_accuracy: 0.7500 - val_loss: 0.5854\n",
            "Epoch 15/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 5s/step - accuracy: 0.8350 - loss: 0.4732 - val_accuracy: 0.7408 - val_loss: 0.7719\n",
            "Epoch 16/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 565ms/step - accuracy: 0.6875 - loss: 0.6587 - val_accuracy: 0.6250 - val_loss: 0.7956\n",
            "Epoch 17/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 5s/step - accuracy: 0.8367 - loss: 0.4833 - val_accuracy: 0.7390 - val_loss: 0.7938\n",
            "Epoch 18/30\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.3838 - val_accuracy: 0.8125 - val_loss: 0.4714\n",
            "Epoch 19/30\n",
            "\u001b[1m41/70\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 4s/step - accuracy: 0.8129 - loss: 0.5384"
          ]
        }
      ]
    }
  ]
}