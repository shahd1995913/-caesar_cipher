{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detection_mask.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNN8a2tNRW5VuFPHbSNih8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahd1995913/-caesar_cipher/blob/main/detection_mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "#Visualization and evaluation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.math import confusion_matrix\n",
        "\n",
        "# Net libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img ,img_to_array\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import  Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "pV4yhIWme4St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/data'\n",
        "example_with_mask = path + 'train/mask/0-with-mask.jpg'\n",
        "example_without_mask = path + 'train/without_mask/1.jpg'\n",
        "\n",
        "# Global Variables\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 8\n",
        "TARGET_SIZE = (128,128)\n",
        "CLASSES = ['Without Mask ','With Mask']"
      ],
      "metadata": {
        "id": "C7AT73Xqgi35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(load_img(example_with_mask))\n"
      ],
      "metadata": {
        "id": "6a5-3rfzgi6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(load_img(example_without_mask))\n"
      ],
      "metadata": {
        "id": "JCYfAXAghq__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=10,\n",
        "                                   width_shift_range=0.2, \n",
        "                                   height_shift_range=0.2,\n",
        "                                   zoom_range=0.25, \n",
        "                                   horizontal_flip=True, \n",
        "                                   samplewise_center=True, \n",
        "                                   samplewise_std_normalization=True,\n",
        "                                   fill_mode='nearest')\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "img = load_img(example_with_mask)\n",
        "example_aug = img_to_array(img)/255.\n",
        "#input have 4 axis - need to add extra empty axis for batch\n",
        "example_aug = example_aug[np.newaxis]\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "for i,img in enumerate(train_datagen.flow(example_aug, batch_size=1)):\n",
        "    plt.subplot(4, 6, i+1)\n",
        "    #remove empty axis \n",
        "    plt.imshow(np.squeeze(img))\n",
        "    \n",
        "    if i == 23:\n",
        "        break\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K20hMANzgi8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_datagen.flow_from_directory(directory= path+'/train', batch_size=BATCH_SIZE, class_mode='categorical', target_size=TARGET_SIZE)\n",
        "validation_set = test_datagen.flow_from_directory(path + '/validation',target_size=TARGET_SIZE)"
      ],
      "metadata": {
        "id": "pxjXQFuBh9O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def craete_model():\n",
        "    \n",
        "    denseNet_model = DenseNet201(input_shape=TARGET_SIZE + (3,), weights='imagenet', include_top=False)\n",
        "    denseNet_model.trainable = False\n",
        "    \n",
        "    flatten = Flatten()(denseNet_model.layers[-1].output)\n",
        "    fc = Dense(units=512, activation='relu')(flatten)\n",
        "    dropout = Dropout(0.35)(fc)\n",
        "    output = Dense(2, activation='softmax')(dropout)\n",
        "   \n",
        "    model = Model(inputs=denseNet_model.input, outputs=output)\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = craete_model()"
      ],
      "metadata": {
        "id": "WPsTVJfyh9Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "starter_learning_rate = 1e-2\n",
        "end_learning_rate = 1e-6\n",
        "decay_steps = 10000\n",
        "learning_rate = optimizers.schedules.PolynomialDecay(starter_learning_rate,decay_steps,end_learning_rate,power=0.4)\n"
      ],
      "metadata": {
        "id": "rD5DlNXOh9Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Optimizer, Loss & Metrics\n",
        "opt = optimizers.Adam(learning_rate=learning_rate)\n",
        "loss = CategoricalCrossentropy()\n",
        "met = 'accuracy'\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer=opt, loss=loss, metrics=[met])"
      ],
      "metadata": {
        "id": "4_wceHurnmEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_callbacks = [\n",
        "                EarlyStopping(monitor='val_accuracy', min_delta=1e-5, patience=5, mode='auto',restore_best_weights=False, verbose=1),\n",
        "                ModelCheckpoint(filepath='my_model.h5', monitor='accuracy', save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch', verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "7B6oPwX9nmHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_set,\n",
        "                    epochs=EPOCHS, steps_per_epoch=len(train_set), # How many mini_batchs we have inside each epoch.\n",
        "                    validation_data=validation_set,\n",
        "                    callbacks=[my_callbacks],\n",
        "                    verbose=1)\n",
        "\n",
        "print('\\n*** Fit is over ***')\n",
        "model.save('my_model.h5')\n",
        "#model.save_weights(\"my_model.h5\")"
      ],
      "metadata": {
        "id": "-Ap7X4hAh9ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = np.array(history.history['loss'])\n",
        "val_loss = np.array(history.history['val_loss'])\n",
        "plt.semilogy(train_loss, label='Train Loss')\n",
        "plt.semilogy(val_loss, label='Validation Loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss - Cross Entropy')\n",
        "plt.title('Train and Validation Loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-oQ74HoLnzHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel('Epoch'),\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZhxC6Sv0n4As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory(path + 'Test',target_size=TARGET_SIZE,shuffle=False)\n"
      ],
      "metadata": {
        "id": "GjJp8gmtn9SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluate \n",
        "loss, accuracy = model.evaluate(test_set)\n",
        "print('Test Accuracy: ', '\\033[1m',round(accuracy*100, 2),'%\\033[0m')"
      ],
      "metadata": {
        "id": "qfl9luGgn9Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# True Label & Predict of a particular Batch\n",
        "image, label = test_set.next()\n",
        "num_imgs = 20\n",
        "lab_names = ['With Mask','Without Mask ']\n",
        "images = image[0:num_imgs,:,:,:]\n",
        "labels = label[0:num_imgs,:]\n",
        "predict = np.round(model.predict(images))\n",
        "\n",
        "image_rows = 4\n",
        "image_col = int(num_imgs/image_rows)\n",
        "\n",
        "_, axs = plt.subplots(image_rows, image_col, figsize=(32,8))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i in range(num_imgs):\n",
        "    img = images[i,:,:,:]\n",
        "    lab = labels[i,:]\n",
        "    axs[i].imshow(img)\n",
        "    pred = predict[i]\n",
        "    axs[i].axis('off')\n",
        "    lab, pred = np.argmax(lab), np.argmax(pred)\n",
        "    axs[i].set_title(label = f'y: {lab_names[lab]}  |  y_pred: {lab_names[pred]}', fontsize=14)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yPIQKxLNoMTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_set).argmax(axis=-1)\n",
        "y_test = test_set.classes\n",
        "\n",
        "Confusion_Matrix = confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "Ta_X_hkhoMee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(25,10))\n",
        "sns.heatmap(Confusion_Matrix,xticklabels=CLASSES,yticklabels=CLASSES, ax=ax, annot=True,fmt=\"1.0f\",cbar=False,annot_kws={\"size\": 40})\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "plt.title(\"Confusion matrix\",fontsize=30)"
      ],
      "metadata": {
        "id": "i0faPEYzoMhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5')"
      ],
      "metadata": {
        "id": "yHDbNd7VoMkj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}